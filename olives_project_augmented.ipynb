{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeafe96",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605609f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad2ced",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class OLIVESDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.transform = transform\n",
    "        self.filtered_data = []\n",
    "        for sample in hf_dataset:\n",
    "            if any(sample.get(k) is None for k in [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\"]):\n",
    "                continue\n",
    "            if sample.get(\"BCVA\") is None or sample.get(\"CST\") is None:\n",
    "                continue\n",
    "            self.filtered_data.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.filtered_data[idx]\n",
    "        image = sample[\"Image\"].convert(\"L\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        labels = torch.tensor([sample[f\"B{i}\"] for i in range(1, 7)], dtype=torch.float32)\n",
    "        extra_features = torch.tensor([sample[\"BCVA\"], sample[\"CST\"]], dtype=torch.float32)\n",
    "        return image, extra_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90156e03",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_data_simple(sample_size=1000, batch_size=16):\n",
    "    olives = load_dataset(\"gOLIVES/OLIVES_Dataset\", \"biomarker_detection\")\n",
    "\n",
    "    train_transform = T.Compose([\n",
    "        T.Resize((256, 256)),\n",
    "        T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=10),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "\n",
    "    test_transform = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "\n",
    "    small_train_data = olives[\"train\"].select(range(sample_size))\n",
    "    full_dataset = OLIVESDataset(hf_dataset=small_train_data, transform=None)\n",
    "\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_subset, val_subset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    # wrap again with transform\n",
    "    train_dataset = OLIVESDataset(hf_dataset=[full_dataset.filtered_data[i] for i in train_subset.indices], transform=train_transform)\n",
    "    val_dataset = OLIVESDataset(hf_dataset=[full_dataset.filtered_data[i] for i in val_subset.indices], transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    test_dataset = OLIVESDataset(hf_dataset=olives[\"test\"], transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31853694",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class MultimodalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.img_out_dim = 2048\n",
    "        self.extra_mlp = nn.Sequential(nn.Linear(2, 64), nn.ReLU(), nn.Linear(64, 128), nn.ReLU())\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(self.img_out_dim + 128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, extra_features):\n",
    "        if image.shape[1] == 1:\n",
    "            image = image.repeat(1, 3, 1, 1)\n",
    "        img_feat = self.cnn(image).view(image.size(0), -1)\n",
    "        extra_feat = self.extra_mlp(extra_features)\n",
    "        combined = torch.cat((img_feat, extra_feat), dim=1)\n",
    "        return self.fusion(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c9cc1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_fold(model, train_loader, val_loader, fold=0, device=\"cuda\", num_epochs=10, lr=1e-4, save_dir=\"checkpoints\"):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f\"best_model_fold_{fold+1}.pt\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, extra_features, labels in train_loader:\n",
    "            images, extra_features, labels = images.to(device), extra_features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(images, extra_features), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, extra_features, labels in val_loader:\n",
    "                images, extra_features, labels = images.to(device), extra_features.to(device), labels.to(device)\n",
    "                val_loss += criterion(model(images, extra_features), labels).item() * images.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        print(f\"Fold {fold+1} | Epoch {epoch+1} | Train Loss: {running_loss/len(train_loader.dataset):.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916671c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_on_test(model, test_loader, device=\"cuda\"):\n",
    "    model = model.to(device).eval()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    all_preds, all_labels = [], []\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, extra_features, labels in test_loader:\n",
    "            images, extra_features, labels = images.to(device), extra_features.to(device), labels.to(device)\n",
    "            outputs = model(images, extra_features)\n",
    "            test_loss += criterion(outputs, labels).item() * images.size(0)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    print(f\"\\n Test Loss: {test_loss / len(test_loader.dataset):.4f}\")\n",
    "    print(f\" Test Accuracy: {accuracy_score(all_labels, all_preds):.4f}\")\n",
    "    print(f\" Test F1 Score (macro): {f1_score(all_labels, all_preds, average='macro'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82134bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sample_sizes = [75000]\n",
    "    for sample_size in sample_sizes:\n",
    "        train_loader, val_loader, test_loader, _ = prepare_data_simple(sample_size=sample_size)\n",
    "        model = MultimodalNet()\n",
    "        train_one_fold(model, train_loader, val_loader, fold=0, num_epochs=40)\n",
    "        evaluate_on_test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
